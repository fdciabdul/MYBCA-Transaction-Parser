{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transaction OCR with PaddleOCR\n",
    "\n",
    "This notebook uses PaddleOCR for optical character recognition on transaction images, then parses the recognized text to extract transaction details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required Packages\n",
    "\n",
    "First, let's install the necessary packages if they're not already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PaddleOCR and dependencies\n",
    "!pip install paddlepaddle -i https://mirror.baidu.com/pypi/simple\n",
    "!pip install \"paddleocr>=2.0.1\" # Recommended to use version 2.0.1+\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import uuid\n",
    "import cv2\n",
    "from paddleocr import PaddleOCR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize PaddleOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PaddleOCR with desired options\n",
    "# Adjust language as needed - use 'en' for English, 'ch' for Chinese, etc.\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en', use_gpu=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define OCR Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_with_paddleocr(image_path):\n",
    "    \"\"\"\n",
    "    Process an image using PaddleOCR and return the OCR results.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file\n",
    "        \n",
    "    Returns:\n",
    "        list: List of detected text with their positions\n",
    "    \"\"\"\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Error: File {image_path} does not exist.\")\n",
    "        return []\n",
    "    \n",
    "    # Read image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Error: Could not read image {image_path}.\")\n",
    "        return []\n",
    "        \n",
    "    # Run OCR\n",
    "    try:\n",
    "        result = ocr.ocr(img, cls=True)\n",
    "        \n",
    "        # Format the result similar to your original API response\n",
    "        formatted_result = []\n",
    "        \n",
    "        # PaddleOCR returns a list of lists where each inner list contains a list of coordinates and [text, confidence]\n",
    "        for line in result[0]:\n",
    "            if len(line) >= 2:  # Ensure proper structure\n",
    "                coordinates = line[0]\n",
    "                text_confidence = line[1]\n",
    "                \n",
    "                entry = {\n",
    "                    \"text\": text_confidence[0],  # The detected text\n",
    "                    \"confidence\": float(text_confidence[1]),  # The confidence score\n",
    "                    \"box\": [\n",
    "                        {\"x\": int(coordinates[j][0]), \"y\": int(coordinates[j][1])} \n",
    "                        for j in range(4)  # Four corners of the bounding box\n",
    "                    ]\n",
    "                }\n",
    "                formatted_result.append(entry)\n",
    "                \n",
    "        return formatted_result\n",
    "    except Exception as e:\n",
    "        print(f\"OCR Error: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Transaction Parsing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_transactions(ocr_text):\n",
    "    \"\"\"\n",
    "    Parse transaction details from OCR text.\n",
    "    \n",
    "    Args:\n",
    "        ocr_text (list): List of OCR results with 'text' keys\n",
    "        \n",
    "    Returns:\n",
    "        list: List of parsed transaction dictionaries\n",
    "    \"\"\"\n",
    "    # Combine all OCR text into a single string\n",
    "    full_text = \" \".join(entry['text'].strip() for entry in ocr_text)\n",
    "    print(f\"Full OCR Text: {full_text}\")  # Debugging output\n",
    "    \n",
    "    # Dynamic regex pattern for transaction details\n",
    "    transaction_pattern = re.compile(\n",
    "        r'(?P<tanggal>\\d{1,2}[\\/\\-]\\d{1,2})\\s+'                         # Match dates like 3/03 or 03-03\n",
    "        r'(?P<name>[A-Za-z\\s]+?)\\-(?P<from_bank>[A-Za-z\\s]+?)\\s+'         # Match names and bank (non-greedy)\n",
    "        r'IDR\\s*(?P<amount>[\\d,\\.]+)\\s+'                                 # Match \"IDR\" and amount with optional spaces\n",
    "        r'.*?(?P<no_rek>\\d{3}\\-\\d{3}\\-[0-9A-Za-z]{4}\\-TAHAPAN)'          # Relax account number to allow digits or letters\n",
    "    )\n",
    "    \n",
    "    matches = transaction_pattern.finditer(full_text)\n",
    "    \n",
    "    transactions = []\n",
    "    for match in matches:\n",
    "        # Normalize date by replacing potential \"O\" with \"0\"\n",
    "        tanggal = match.group(\"tanggal\").replace(\"O\", \"0\")\n",
    "        \n",
    "        raw_amount = match.group(\"amount\")\n",
    "        # Remove common thousand separators and periods\n",
    "        normalized_amount = raw_amount.replace('.', '').replace(',', '')\n",
    "        # Adjust the amount if necessary (this example divides by 100)\n",
    "        amount = int(normalized_amount) // 100\n",
    "        \n",
    "        transaction = {\n",
    "            \"tanggal\": tanggal,\n",
    "            \"name\": match.group(\"name\").strip(),\n",
    "            \"from_bank\": match.group(\"from_bank\").strip(),\n",
    "            \"amount\": amount,\n",
    "            \"no_rek\": match.group(\"no_rek\")\n",
    "        }\n",
    "        transactions.append(transaction)\n",
    "    \n",
    "    return transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_ocr_results(image_path, ocr_results):\n",
    "    \"\"\"\n",
    "    Visualize OCR results on the image.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the original image\n",
    "        ocr_results (list): OCR results with text and bounding box information\n",
    "    \"\"\"\n",
    "    # Read the image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Error: Could not read image {image_path} for visualization.\")\n",
    "        return\n",
    "        \n",
    "    # Convert to RGB for matplotlib display\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Create a copy for drawing\n",
    "    img_with_boxes = img_rgb.copy()\n",
    "    \n",
    "    # Draw bounding boxes and text\n",
    "    for entry in ocr_results:\n",
    "        if 'box' in entry and len(entry['box']) == 4:\n",
    "            # Convert box points to numpy array of points\n",
    "            box_points = np.array([[p['x'], p['y']] for p in entry['box']], dtype=np.int32)\n",
    "            \n",
    "            # Draw polygon\n",
    "            cv2.polylines(img_with_boxes, [box_points], True, (0, 255, 0), 2)\n",
    "            \n",
    "            # Add text near the top-left corner\n",
    "            text_position = (box_points[0][0], box_points[0][1] - 10)\n",
    "            cv2.putText(img_with_boxes, entry['text'][:20], text_position, \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "    \n",
    "    # Display the image\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(img_with_boxes)\n",
    "    plt.title(\"OCR Results Visualization\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_transaction_image(image_path, visualize=True):\n",
    "    \"\"\"\n",
    "    Process a transaction image: perform OCR, parse transactions, and optionally visualize results.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the transaction image\n",
    "        visualize (bool): Whether to visualize the OCR results\n",
    "        \n",
    "    Returns:\n",
    "        list: List of parsed transactions\n",
    "    \"\"\"\n",
    "    # Step 1: Process the image with PaddleOCR\n",
    "    ocr_results = process_image_with_paddleocr(image_path)\n",
    "    \n",
    "    if not ocr_results:\n",
    "        print(\"No OCR results found.\")\n",
    "        return []\n",
    "    \n",
    "    # Step 2: Visualize OCR results if requested\n",
    "    if visualize:\n",
    "        visualize_ocr_results(image_path, ocr_results)\n",
    "    \n",
    "    # Step 3: Parse transactions from OCR text\n",
    "    transactions = parse_transactions(ocr_results)\n",
    "    \n",
    "    # Step 4: Display parsed transactions\n",
    "    print(f\"\\nParsed {len(transactions)} transactions:\")\n",
    "    for i, transaction in enumerate(transactions, 1):\n",
    "        print(f\"Transaction {i}:\")\n",
    "        for key, value in transaction.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        print()\n",
    "    \n",
    "    return transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Sample Images\n",
    "\n",
    "Replace 'your_transaction_image.jpg' with your actual transaction image path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your transaction image\n",
    "image_path = 'your_transaction_image.jpg'\n",
    "\n",
    "# Process the image\n",
    "transactions = process_transaction_image(image_path)\n",
    "\n",
    "# Save results to JSON if desired\n",
    "if transactions:\n",
    "    output_file = f\"transactions_{uuid.uuid4()}.json\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(transactions, f, indent=2)\n",
    "    print(f\"Saved transactions to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Multiple Images (Optional)\n",
    "\n",
    "If you have multiple transaction images to process, you can use the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_transaction_folder(folder_path, extensions=['jpg', 'jpeg', 'png']):\n",
    "    \"\"\"\n",
    "    Process all transaction images in a folder.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing transaction images\n",
    "        extensions (list): List of valid image extensions to process\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary mapping image filenames to their transactions\n",
    "    \"\"\"\n",
    "    all_transactions = {}\n",
    "    \n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Error: Folder {folder_path} does not exist.\")\n",
    "        return all_transactions\n",
    "    \n",
    "    # Process each image file in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Check if the file has a valid extension\n",
    "        if any(filename.lower().endswith(f'.{ext}') for ext in extensions):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            print(f\"\\nProcessing {filename}...\")\n",
    "            \n",
    "            # Process the image\n",
    "            transactions = process_transaction_image(image_path, visualize=True)\n",
    "            \n",
    "            # Add to results dictionary\n",
    "            all_transactions[filename] = transactions\n",
    "    \n",
    "    # Save all results to a single JSON file\n",
    "    if all_transactions:\n",
    "        output_file = f\"all_transactions_{uuid.uuid4()}.json\"\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(all_transactions, f, indent=2)\n",
    "        print(f\"\\nSaved all transactions to {output_file}\")\n",
    "    \n",
    "    return all_transactions\n",
    "\n",
    "# Uncomment and modify the following line to process a folder of images\n",
    "# folder_transactions = process_transaction_folder('your_transaction_images_folder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving OCR Results (Optional)\n",
    "\n",
    "If you're having issues with OCR accuracy, you can try preprocessing the images before running OCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    \"\"\"\n",
    "    Preprocess an image to improve OCR results.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Preprocessed image\n",
    "    \"\"\"\n",
    "    # Read the image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Error: Could not read image {image_path}.\")\n",
    "        return None\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply thresholding to get binary image\n",
    "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Optional: Apply noise reduction\n",
    "    denoised = cv2.fastNlMeansDenoising(binary, None, 10, 7, 21)\n",
    "    \n",
    "    # Optional: Apply dilation to make text thicker\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    dilated = cv2.dilate(denoised, kernel, iterations=1)\n",
    "    \n",
    "    # Display preprocessing stages\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    axes[0, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    axes[0, 0].set_title('Original')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    axes[0, 1].imshow(gray, cmap='gray')\n",
    "    axes[0, 1].set_title('Grayscale')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    axes[1, 0].imshow(binary, cmap='gray')\n",
    "    axes[1, 0].set_title('Binary (Thresholded)')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    axes[1, 1].imshow(dilated, cmap='gray')\n",
    "    axes[1, 1].set_title('Dilated')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the preprocessed image temporarily\n",
    "    preprocessed_path = f\"preprocessed_{os.path.basename(image_path)}\"\n",
    "    cv2.imwrite(preprocessed_path, dilated)\n",
    "    print(f\"Saved preprocessed image to {preprocessed_path}\")\n",
    "    \n",
    "    return preprocessed_path\n",
    "\n",
    "# Example usage:\n",
    "# preprocessed_image_path = preprocess_image('your_transaction_image.jpg')\n",
    "# if preprocessed_image_path:\n",
    "#     transactions = process_transaction_image(preprocessed_image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
